{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Folder Structure"
      ],
      "metadata": {
        "id": "CdPnxNdMHw9u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nqBHwm1eTm9q"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ],
      "metadata": {
        "id": "kRvUBGh0H4wU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME),\n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'),\n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'),\n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'),\n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
        " }"
      ],
      "metadata": {
        "id": "bHgURDAFH6Iq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ],
      "metadata": {
        "id": "QNcu2wEjH7Hr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ],
      "metadata": {
        "id": "DdCOeF_KH8L7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download / Upload Dataset"
      ],
      "metadata": {
        "id": "dkXZv7T8IBCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "vkHdbEiqH9LL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mv /content/kaggle.json ~/.kaggle"
      ],
      "metadata": {
        "id": "mLr8eq0aKNEa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d kishanj/simple-object-detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA3OrDZ-KSa8",
        "outputId": "cbd83843-3992-4b91-d9b7-905ef2739096"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading simple-object-detection.zip to /content\n",
            "  0% 0.00/618k [00:00<?, ?B/s]\n",
            "100% 618k/618k [00:00<00:00, 170MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! unzip /content/simple-object-detection.zip"
      ],
      "metadata": {
        "id": "YxG42igxK-Gr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm /content/simple-object-detection.zip"
      ],
      "metadata": {
        "id": "pPwqjDBcLBIy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "id": "YmJf6WDNRUjB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_folder = \"/content/datasets/annotations\"\n",
        "destination_folder = \"/content/datasets/images\"\n",
        "\n",
        "all_files = os.listdir(source_folder)\n",
        "\n",
        "for file in all_files:\n",
        "    source_path = os.path.join(source_folder, file)\n",
        "    destination_path = os.path.join(destination_folder, file)\n",
        "    shutil.move(source_path, destination_path)"
      ],
      "metadata": {
        "id": "4qx2z93ORV5A"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "destination_folder = \"/content/datasets/annotations\"\n",
        "source_folder = \"/content/datasets/images\"\n",
        "\n",
        "all_files = sorted(os.listdir(source_folder))\n",
        "count = 0\n",
        "\n",
        "for f in range(0,len(all_files),20) :\n",
        "    count = count +1\n",
        "    for fi in [f, f+1] :\n",
        "        file = all_files[fi]\n",
        "        source_path = os.path.join(source_folder, file)\n",
        "        destination_path = os.path.join(destination_folder, file)\n",
        "        shutil.move(source_path, destination_path)\n",
        "\n",
        "print(\"Number of Records for Testing : \",count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbKx_7beUdsB",
        "outputId": "562b1943-184b-4930-f967-c2d51d119fd8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Records for Testing :  12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mv /content/datasets/annotations {paths['IMAGE_PATH']+'/test'}"
      ],
      "metadata": {
        "id": "n8Q_TybTUFKf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mv /content/datasets/images {paths['IMAGE_PATH']+'/train'}"
      ],
      "metadata": {
        "id": "XmiysSHZULnx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r /content/datasets"
      ],
      "metadata": {
        "id": "L_07L5TyLngx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dowload Pre-Trained Model Weights"
      ],
      "metadata": {
        "id": "a6UrQ2FGIJdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.name=='nt':\n",
        "    !pip install wget\n",
        "    import wget"
      ],
      "metadata": {
        "id": "3HkgYPtbIQ9i"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikwYQaL1ITV6",
        "outputId": "6944113e-8093-4187-b4c4-20585f5d4e79"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/models'...\n",
            "remote: Enumerating objects: 87218, done.\u001b[K\n",
            "remote: Counting objects: 100% (972/972), done.\u001b[K\n",
            "remote: Compressing objects: 100% (463/463), done.\u001b[K\n",
            "remote: Total 87218 (delta 562), reused 874 (delta 499), pack-reused 86246\u001b[K\n",
            "Receiving objects: 100% (87218/87218), 599.20 MiB | 21.40 MiB/s, done.\n",
            "Resolving deltas: 100% (62444/62444), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Tensorflow Object Detection\n",
        "if os.name=='posix':\n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install .\n",
        "\n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dCVMckvIWCS",
        "outputId": "ac54f411-8872-47bd-ea37-cb2ff221d819"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.12.4-1ubuntu7.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n",
            "Processing /content/Tensorflow/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3 (from object-detection==0.1)\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam (from object-detection==0.1)\n",
            "  Downloading apache_beam-2.49.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (9.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (4.9.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.7.1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (0.29.36)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (21.6.0)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.0.7)\n",
            "Collecting lvis (from object-detection==0.1)\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.5.3)\n",
            "Collecting tf-models-official>=2.5.1 (from object-detection==0.1)\n",
            "  Downloading tf_models_official-2.13.1-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_io (from object-detection==0.1)\n",
            "  Downloading tensorflow_io-0.33.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.6/28.6 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.12.0)\n",
            "Collecting pyparsing==2.4.7 (from object-detection==0.1)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0 (from object-detection==0.1)\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu<=2.2.0->object-detection==0.1)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.23.5)\n",
            "Collecting colorama (from sacrebleu<=2.2.0->object-detection==0.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.84.0)\n",
            "Collecting immutabledict (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading immutabledict-3.0.0-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.16)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.0.76)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (9.0.0)\n",
            "Collecting pyyaml<5.4.0,>=5.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.4/269.4 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.9.2)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.14.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-text~=2.13.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow~=2.13.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2023.3)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam->object-detection==0.1)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson<4.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading orjson-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam->object-detection==0.1)\n",
            "  Downloading fastavro-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners<1.0,>=0.3 (from apache-beam->object-detection==0.1)\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.57.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading hdfs-2.7.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.22.0)\n",
            "Collecting objsize<0.7.0,>=0.6.1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading pymongo-4.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (603 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m603.6/603.6 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.22.3)\n",
            "Requirement already satisfied: protobuf<4.24.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.7.1)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<12.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (4.8.0.76)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (4.42.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (23.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.33.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object-detection==0.1) (0.33.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2023.7.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.0.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object-detection==0.1)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.4)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.9.0)\n",
            "Collecting keras (from object-detection==0.1)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (67.7.2)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.3.0)\n",
            "Collecting typing-extensions>=3.7.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.1.6)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.41.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (6.0.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.16.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.60.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.3.7)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, hdfs, pyyaml, seqeval, docopt\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697181 sha256=3e1c3026117047563bb3ab1ff6e369149410a70902e9c9738849f5dec12d65e8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t9z9vd5g/wheels/fb/c9/43/709f88e66b36649c7a29812ca4f6236f31caed949aabc3e335\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43991 sha256=70cd6f33bacd29d367b4f5719fea5f11b0dd7ce77893e89250614e4da4819bc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31408 sha256=2e757439b1716a8f50afe155e5af689f043a50a67277c2630c58456a7e98e301\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78541 sha256=26439c83c05174fb33c8b9681ac8164a49fb74694a9c5f08c99e506b1a04b541\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.2-py3-none-any.whl size=34168 sha256=f6d7558025c0ed55647dbba35be24f8dc0e3592ab79360a4a51ada3cdc6fded3\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/39/8e/e1905de9af8ae74911cd3e53e721995cd230816f63776e5825\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp310-cp310-linux_x86_64.whl size=44637 sha256=c27d5ba21ce5eada4dd3a612c5d2d62c296f2abd204b136da90fcc0d5d53c1e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/a9/6a/d0a6981a8dbb698845178818642f72ce179f14336908c7df01\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=c21936e225092c81bb5fd1d33bd60551c9da60f2014fa7b6debc0eccb3299f9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=2d2c6fcc77e62e10316c0ee0917a236150402d2ccf720e042db330878595c7a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built object-detection avro-python3 crcmod dill hdfs pyyaml seqeval docopt\n",
            "Installing collected packages: sentencepiece, docopt, crcmod, zstandard, typing-extensions, tensorflow-model-optimization, tensorflow_io, tensorflow-estimator, pyyaml, pyparsing, portalocker, orjson, objsize, keras, immutabledict, fasteners, fastavro, dnspython, dill, colorama, avro-python3, sacrebleu, pymongo, hdfs, seqeval, lvis, apache-beam, tensorboard, tensorflow, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.1\n",
            "    Uninstalling PyYAML-6.0.1:\n",
            "      Successfully uninstalled PyYAML-6.0.1\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flax 0.7.2 requires PyYAML>=5.4.1, but you have pyyaml 5.3.1 which is incompatible.\n",
            "pydantic 2.1.1 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.4.0 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed apache-beam-2.49.0 avro-python3-1.10.2 colorama-0.4.6 crcmod-1.7 dill-0.3.1.1 dnspython-2.4.2 docopt-0.6.2 fastavro-1.8.2 fasteners-0.18 hdfs-2.7.2 immutabledict-3.0.0 keras-2.13.1 lvis-0.5.3 object-detection-0.1 objsize-0.6.1 orjson-3.9.5 portalocker-2.7.0 pymongo-4.4.1 pyparsing-2.4.7 pyyaml-5.3.1 sacrebleu-2.2.0 sentencepiece-0.1.99 seqeval-1.2.2 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.13.0 tensorflow_io-0.33.0 tf-models-official-2.13.1 typing-extensions-4.5.0 zstandard-0.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZsGUI6sIYUq",
        "outputId": "fea6fc03-2b59-4936-c95c-d3a7c25e089f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-19 08:23:55.242058: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-19 08:23:56.427191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-08-19 08:23:59.523329: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-19 08:24:00.071831: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-19 08:24:00.072263: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Running tests under Python 3.10.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2023-08-19 08:24:00.083505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-19 08:24:00.083874: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-19 08:24:00.084162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-19 08:24:01.335465: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-19 08:24:01.335897: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-19 08:24:01.336145: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-19 08:24:01.336317: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-08-19 08:24:01.336358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13692 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W0819 08:24:01.556364 136955001065472 batch_normalization.py:1531] `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W0819 08:24:01.840383 136955001065472 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.08s\n",
            "I0819 08:24:02.153786 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.1s\n",
            "I0819 08:24:03.249809 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 1.09s\n",
            "I0819 08:24:04.335956 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 1.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 1.72s\n",
            "I0819 08:24:06.052968 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 1.72s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 6.58s\n",
            "I0819 08:24:12.632412 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 6.58s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0819 08:24:12.651578 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.1s\n",
            "I0819 08:24:12.754660 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.06s\n",
            "I0819 08:24:12.813065 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.06s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.06s\n",
            "I0819 08:24:12.873868 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.06s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.48s\n",
            "I0819 08:24:13.355557 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.48s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.38s\n",
            "I0819 08:24:13.737624 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.38s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.38s\n",
            "I0819 08:24:14.114596 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.38s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.51s\n",
            "I0819 08:24:14.627220 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.51s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.36s\n",
            "I0819 08:24:14.997149 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.36s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.1s\n",
            "I0819 08:24:15.105349 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0819 08:24:15.954897 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0819 08:24:15.955101 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 64\n",
            "I0819 08:24:15.955207 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 3\n",
            "I0819 08:24:15.959488 136955001065472 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0819 08:24:16.021823 136955001065472 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0819 08:24:16.022006 136955001065472 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0819 08:24:16.147612 136955001065472 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0819 08:24:16.147804 136955001065472 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0819 08:24:16.505462 136955001065472 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0819 08:24:16.505676 136955001065472 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0819 08:24:16.840835 136955001065472 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0819 08:24:16.841035 136955001065472 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0819 08:24:17.665262 136955001065472 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0819 08:24:17.665480 136955001065472 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0819 08:24:18.459197 136955001065472 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0819 08:24:18.459407 136955001065472 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0819 08:24:19.300323 136955001065472 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0819 08:24:19.300574 136955001065472 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0819 08:24:19.465936 136955001065472 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0819 08:24:19.537318 136955001065472 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0819 08:24:19.631194 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0819 08:24:19.631388 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n",
            "I0819 08:24:19.631470 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 4\n",
            "I0819 08:24:19.634392 136955001065472 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0819 08:24:19.661653 136955001065472 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0819 08:24:19.661778 136955001065472 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0819 08:24:19.898198 136955001065472 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0819 08:24:19.898401 136955001065472 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0819 08:24:20.372474 136955001065472 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0819 08:24:20.372714 136955001065472 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0819 08:24:21.114734 136955001065472 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0819 08:24:21.114980 136955001065472 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0819 08:24:22.105871 136955001065472 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0819 08:24:22.106074 136955001065472 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0819 08:24:23.054286 136955001065472 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0819 08:24:23.054532 136955001065472 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0819 08:24:23.894670 136955001065472 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0819 08:24:23.894834 136955001065472 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0819 08:24:24.082997 136955001065472 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0819 08:24:24.115563 136955001065472 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0819 08:24:24.189932 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0819 08:24:24.190070 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 112\n",
            "I0819 08:24:24.190144 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 5\n",
            "I0819 08:24:24.192095 136955001065472 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0819 08:24:24.209717 136955001065472 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0819 08:24:24.209839 136955001065472 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0819 08:24:24.346364 136955001065472 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0819 08:24:24.346500 136955001065472 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0819 08:24:24.621531 136955001065472 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0819 08:24:24.621683 136955001065472 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0819 08:24:24.898307 136955001065472 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0819 08:24:24.898461 136955001065472 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0819 08:24:25.258936 136955001065472 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0819 08:24:25.259088 136955001065472 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0819 08:24:25.635466 136955001065472 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0819 08:24:25.635624 136955001065472 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0819 08:24:26.131526 136955001065472 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0819 08:24:26.131709 136955001065472 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0819 08:24:26.404917 136955001065472 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0819 08:24:26.455966 136955001065472 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0819 08:24:26.562882 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0819 08:24:26.563054 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 160\n",
            "I0819 08:24:26.563128 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 6\n",
            "I0819 08:24:26.566155 136955001065472 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0819 08:24:26.594337 136955001065472 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0819 08:24:26.594466 136955001065472 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0819 08:24:26.817394 136955001065472 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0819 08:24:26.817575 136955001065472 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0819 08:24:27.201335 136955001065472 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0819 08:24:27.201549 136955001065472 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0819 08:24:27.578046 136955001065472 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0819 08:24:27.578223 136955001065472 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0819 08:24:28.237445 136955001065472 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0819 08:24:28.237651 136955001065472 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0819 08:24:28.929176 136955001065472 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0819 08:24:28.929370 136955001065472 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0819 08:24:29.763142 136955001065472 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0819 08:24:29.763484 136955001065472 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0819 08:24:30.043892 136955001065472 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0819 08:24:30.107811 136955001065472 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0819 08:24:30.223296 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0819 08:24:30.223460 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 224\n",
            "I0819 08:24:30.223570 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
            "I0819 08:24:30.226707 136955001065472 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0819 08:24:30.257270 136955001065472 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0819 08:24:30.257396 136955001065472 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0819 08:24:30.477777 136955001065472 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0819 08:24:30.477941 136955001065472 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0819 08:24:31.029708 136955001065472 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0819 08:24:31.029895 136955001065472 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0819 08:24:31.609462 136955001065472 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0819 08:24:31.609671 136955001065472 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0819 08:24:32.763784 136955001065472 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0819 08:24:32.763962 136955001065472 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0819 08:24:33.594609 136955001065472 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0819 08:24:33.594803 136955001065472 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0819 08:24:34.703228 136955001065472 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0819 08:24:34.703425 136955001065472 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0819 08:24:35.006172 136955001065472 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0819 08:24:35.067047 136955001065472 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0819 08:24:35.200021 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0819 08:24:35.200197 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 288\n",
            "I0819 08:24:35.200281 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
            "I0819 08:24:35.203275 136955001065472 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0819 08:24:35.230871 136955001065472 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0819 08:24:35.231005 136955001065472 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0819 08:24:35.557125 136955001065472 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0819 08:24:35.557315 136955001065472 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0819 08:24:36.234070 136955001065472 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0819 08:24:36.234264 136955001065472 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0819 08:24:36.913321 136955001065472 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0819 08:24:36.913478 136955001065472 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0819 08:24:37.559505 136955001065472 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0819 08:24:37.559678 136955001065472 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0819 08:24:38.194477 136955001065472 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0819 08:24:38.194646 136955001065472 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0819 08:24:39.063910 136955001065472 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0819 08:24:39.064070 136955001065472 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0819 08:24:39.361496 136955001065472 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0819 08:24:39.402552 136955001065472 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0819 08:24:39.495578 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0819 08:24:39.495716 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I0819 08:24:39.495788 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
            "I0819 08:24:39.497634 136955001065472 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0819 08:24:39.517773 136955001065472 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0819 08:24:39.517889 136955001065472 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0819 08:24:39.748595 136955001065472 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0819 08:24:39.748750 136955001065472 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0819 08:24:40.294435 136955001065472 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0819 08:24:40.294607 136955001065472 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0819 08:24:40.858429 136955001065472 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0819 08:24:40.858600 136955001065472 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0819 08:24:41.610919 136955001065472 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0819 08:24:41.611070 136955001065472 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0819 08:24:42.625805 136955001065472 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0819 08:24:42.625959 136955001065472 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0819 08:24:43.639830 136955001065472 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0819 08:24:43.639985 136955001065472 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0819 08:24:43.925289 136955001065472 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0819 08:24:43.962700 136955001065472 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0819 08:24:44.065682 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0819 08:24:44.065821 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I0819 08:24:44.065891 136955001065472 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
            "I0819 08:24:44.067701 136955001065472 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0819 08:24:44.086886 136955001065472 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0819 08:24:44.086989 136955001065472 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0819 08:24:44.382219 136955001065472 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0819 08:24:44.382378 136955001065472 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0819 08:24:45.004307 136955001065472 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0819 08:24:45.004461 136955001065472 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0819 08:24:45.625779 136955001065472 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0819 08:24:45.625931 136955001065472 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0819 08:24:46.520043 136955001065472 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0819 08:24:46.520195 136955001065472 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0819 08:24:47.619423 136955001065472 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0819 08:24:47.619622 136955001065472 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0819 08:24:49.292833 136955001065472 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0819 08:24:49.293025 136955001065472 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0819 08:24:49.861288 136955001065472 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0819 08:24:49.919144 136955001065472 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 35.02s\n",
            "I0819 08:24:50.127902 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 35.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0819 08:24:50.171975 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0819 08:24:50.174615 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0819 08:24:50.175251 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0819 08:24:50.177333 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0819 08:24:50.179245 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0819 08:24:50.179831 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0819 08:24:50.181225 136955001065472 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 50.105s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import object_detection"
      ],
      "metadata": {
        "id": "JGvFYpW3Iaqy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suTsDtmJIdWi",
        "outputId": "8e50d842-c8ee-40e9-f43f-0e849e5858a4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-19 08:24:52--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 108.177.98.128, 2607:f8b0:400e:c06::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|108.177.98.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.56M   116MB/s    in 0.2s    \n",
            "\n",
            "2023-08-19 08:24:53 (116 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
            "\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Label Map"
      ],
      "metadata": {
        "id": "4_HxkQ7fJOoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [{'name':'star', 'id':1}]\n",
        "\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ],
      "metadata": {
        "id": "YIZBkzDBJMUS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create TF-Records of Dataset"
      ],
      "metadata": {
        "id": "KSGfHy8IJXnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
        "if os.path.exists(ARCHIVE_FILES):\n",
        "  !tar -zxvf {ARCHIVE_FILES}"
      ],
      "metadata": {
        "id": "zbwbDhCUJa5C"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAk3xVJ4JdIH",
        "outputId": "5f90ca11-6760-472c-d82b-787286d33862"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/scripts'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')}\n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ele_RVqbJd9I",
        "outputId": "f3b94e1d-61c8-4575-fb9c-fe4104056738"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Update Model Training Config File"
      ],
      "metadata": {
        "id": "7X3UYGn-JiyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.name =='posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ],
      "metadata": {
        "id": "ci99YSjmJmSv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ],
      "metadata": {
        "id": "6O-DsiJDJpPI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ],
      "metadata": {
        "id": "qBmCCwcvJrUL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5FMwor2JuSh",
        "outputId": "a762f070-5bbf-482c-8bd7-8e35033f0bcd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 320\n",
              "       width: 320\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " },\n",
              " 'train_config': batch_size: 128\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 50000\n",
              "         warmup_learning_rate: 0.026666000485420227\n",
              "         warmup_steps: 1000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " fine_tune_checkpoint_version: V2,\n",
              " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " },\n",
              " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false,\n",
              " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }\n",
              " ],\n",
              " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:\n",
        "    proto_str = f.read()\n",
        "    text_format.Merge(proto_str, pipeline_config)"
      ],
      "metadata": {
        "id": "1w2HXpQdJwqq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ],
      "metadata": {
        "id": "Bf0t1HNDJyOB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:\n",
        "    f.write(config_text)"
      ],
      "metadata": {
        "id": "KY4uz0hVJ0HK"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "97dWF531J9HL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ],
      "metadata": {
        "id": "DGw0qlNnJ8zK"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ],
      "metadata": {
        "id": "SNp1XOJSKBJq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(command)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNi8Cj_uKCDT",
        "outputId": "41c47020-271a-45a2-8b50-d939eee8d290"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{command}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqNq2QPiKCoy",
        "outputId": "551edd20-05ec-40b2-bc22-bfcc4d594358"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-19 08:25:21.622929: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-08-19 08:25:25.355356: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0819 08:25:25.356258 136251198717952 mirrored_strategy.py:419] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 2000\n",
            "I0819 08:25:25.378083 136251198717952 config_util.py:552] Maybe overwriting train_steps: 2000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0819 08:25:25.378259 136251198717952 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0819 08:25:25.557008 136251198717952 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0819 08:25:25.564272 136251198717952 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0819 08:25:25.564440 136251198717952 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0819 08:25:25.564529 136251198717952 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0819 08:25:25.564601 136251198717952 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0819 08:25:25.571151 136251198717952 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0819 08:25:25.588925 136251198717952 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0819 08:25:31.642144 136251198717952 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0819 08:25:36.119380 136251198717952 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0819 08:25:38.596957 136251198717952 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "I0819 08:25:48.125893 136246210852416 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "I0819 08:26:00.511161 136246210852416 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0819 08:26:14.336917 136251198717952 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0819 08:26:14.339552 136251198717952 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0819 08:26:14.340602 136251198717952 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0819 08:26:14.341505 136251198717952 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0819 08:26:14.345112 136251198717952 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0819 08:26:14.346085 136251198717952 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0819 08:26:14.347045 136251198717952 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0819 08:26:14.347987 136251198717952 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0819 08:26:14.352464 136251198717952 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0819 08:26:14.353412 136251198717952 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0819 08:26:15.912470 136246380340800 deprecation.py:569] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "I0819 08:26:17.667032 136246380340800 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "I0819 08:26:25.454019 136246380340800 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "I0819 08:26:30.152335 136246380340800 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "I0819 08:26:36.430664 136246380340800 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "INFO:tensorflow:Step 100 per-step time 0.434s\n",
            "I0819 08:26:58.697682 136251198717952 model_lib_v2.py:705] Step 100 per-step time 0.434s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1729605,\n",
            " 'Loss/localization_loss': 0.1880418,\n",
            " 'Loss/regularization_loss': 0.15510136,\n",
            " 'Loss/total_loss': 0.5161037,\n",
            " 'learning_rate': 0.0319994}\n",
            "I0819 08:26:58.698087 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.1729605,\n",
            " 'Loss/localization_loss': 0.1880418,\n",
            " 'Loss/regularization_loss': 0.15510136,\n",
            " 'Loss/total_loss': 0.5161037,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Step 200 per-step time 0.067s\n",
            "I0819 08:27:05.421983 136251198717952 model_lib_v2.py:705] Step 200 per-step time 0.067s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13226022,\n",
            " 'Loss/localization_loss': 0.10803482,\n",
            " 'Loss/regularization_loss': 0.15482704,\n",
            " 'Loss/total_loss': 0.39512208,\n",
            " 'learning_rate': 0.0373328}\n",
            "I0819 08:27:05.422350 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.13226022,\n",
            " 'Loss/localization_loss': 0.10803482,\n",
            " 'Loss/regularization_loss': 0.15482704,\n",
            " 'Loss/total_loss': 0.39512208,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Step 300 per-step time 0.058s\n",
            "I0819 08:27:11.247278 136251198717952 model_lib_v2.py:705] Step 300 per-step time 0.058s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10743548,\n",
            " 'Loss/localization_loss': 0.071586944,\n",
            " 'Loss/regularization_loss': 0.15445937,\n",
            " 'Loss/total_loss': 0.3334818,\n",
            " 'learning_rate': 0.0426662}\n",
            "I0819 08:27:11.247588 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.10743548,\n",
            " 'Loss/localization_loss': 0.071586944,\n",
            " 'Loss/regularization_loss': 0.15445937,\n",
            " 'Loss/total_loss': 0.3334818,\n",
            " 'learning_rate': 0.0426662}\n",
            "INFO:tensorflow:Step 400 per-step time 0.054s\n",
            "I0819 08:27:16.678905 136251198717952 model_lib_v2.py:705] Step 400 per-step time 0.054s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13965137,\n",
            " 'Loss/localization_loss': 0.05804518,\n",
            " 'Loss/regularization_loss': 0.15407227,\n",
            " 'Loss/total_loss': 0.35176882,\n",
            " 'learning_rate': 0.047999598}\n",
            "I0819 08:27:16.679191 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.13965137,\n",
            " 'Loss/localization_loss': 0.05804518,\n",
            " 'Loss/regularization_loss': 0.15407227,\n",
            " 'Loss/total_loss': 0.35176882,\n",
            " 'learning_rate': 0.047999598}\n",
            "INFO:tensorflow:Step 500 per-step time 0.061s\n",
            "I0819 08:27:22.777959 136251198717952 model_lib_v2.py:705] Step 500 per-step time 0.061s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09631117,\n",
            " 'Loss/localization_loss': 0.033332057,\n",
            " 'Loss/regularization_loss': 0.15357083,\n",
            " 'Loss/total_loss': 0.28321406,\n",
            " 'learning_rate': 0.053333}\n",
            "I0819 08:27:22.778328 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.09631117,\n",
            " 'Loss/localization_loss': 0.033332057,\n",
            " 'Loss/regularization_loss': 0.15357083,\n",
            " 'Loss/total_loss': 0.28321406,\n",
            " 'learning_rate': 0.053333}\n",
            "INFO:tensorflow:Step 600 per-step time 0.064s\n",
            "I0819 08:27:29.192989 136251198717952 model_lib_v2.py:705] Step 600 per-step time 0.064s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13253191,\n",
            " 'Loss/localization_loss': 0.09613859,\n",
            " 'Loss/regularization_loss': 0.15306154,\n",
            " 'Loss/total_loss': 0.38173205,\n",
            " 'learning_rate': 0.0586664}\n",
            "I0819 08:27:29.193361 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.13253191,\n",
            " 'Loss/localization_loss': 0.09613859,\n",
            " 'Loss/regularization_loss': 0.15306154,\n",
            " 'Loss/total_loss': 0.38173205,\n",
            " 'learning_rate': 0.0586664}\n",
            "INFO:tensorflow:Step 700 per-step time 0.055s\n",
            "I0819 08:27:34.653187 136251198717952 model_lib_v2.py:705] Step 700 per-step time 0.055s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07155769,\n",
            " 'Loss/localization_loss': 0.037737213,\n",
            " 'Loss/regularization_loss': 0.15246795,\n",
            " 'Loss/total_loss': 0.26176286,\n",
            " 'learning_rate': 0.0639998}\n",
            "I0819 08:27:34.653468 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.07155769,\n",
            " 'Loss/localization_loss': 0.037737213,\n",
            " 'Loss/regularization_loss': 0.15246795,\n",
            " 'Loss/total_loss': 0.26176286,\n",
            " 'learning_rate': 0.0639998}\n",
            "INFO:tensorflow:Step 800 per-step time 0.055s\n",
            "I0819 08:27:40.192956 136251198717952 model_lib_v2.py:705] Step 800 per-step time 0.055s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08019187,\n",
            " 'Loss/localization_loss': 0.028444251,\n",
            " 'Loss/regularization_loss': 0.15184593,\n",
            " 'Loss/total_loss': 0.26048207,\n",
            " 'learning_rate': 0.069333196}\n",
            "I0819 08:27:40.193346 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.08019187,\n",
            " 'Loss/localization_loss': 0.028444251,\n",
            " 'Loss/regularization_loss': 0.15184593,\n",
            " 'Loss/total_loss': 0.26048207,\n",
            " 'learning_rate': 0.069333196}\n",
            "INFO:tensorflow:Step 900 per-step time 0.065s\n",
            "I0819 08:27:46.677404 136251198717952 model_lib_v2.py:705] Step 900 per-step time 0.065s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.073644266,\n",
            " 'Loss/localization_loss': 0.022804083,\n",
            " 'Loss/regularization_loss': 0.15112534,\n",
            " 'Loss/total_loss': 0.24757369,\n",
            " 'learning_rate': 0.074666604}\n",
            "I0819 08:27:46.677797 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.073644266,\n",
            " 'Loss/localization_loss': 0.022804083,\n",
            " 'Loss/regularization_loss': 0.15112534,\n",
            " 'Loss/total_loss': 0.24757369,\n",
            " 'learning_rate': 0.074666604}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.062s\n",
            "I0819 08:27:52.834429 136251198717952 model_lib_v2.py:705] Step 1000 per-step time 0.062s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06626707,\n",
            " 'Loss/localization_loss': 0.03437241,\n",
            " 'Loss/regularization_loss': 0.15037772,\n",
            " 'Loss/total_loss': 0.2510172,\n",
            " 'learning_rate': 0.08}\n",
            "I0819 08:27:52.834724 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.06626707,\n",
            " 'Loss/localization_loss': 0.03437241,\n",
            " 'Loss/regularization_loss': 0.15037772,\n",
            " 'Loss/total_loss': 0.2510172,\n",
            " 'learning_rate': 0.08}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.067s\n",
            "I0819 08:27:59.535989 136251198717952 model_lib_v2.py:705] Step 1100 per-step time 0.067s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0580084,\n",
            " 'Loss/localization_loss': 0.018732186,\n",
            " 'Loss/regularization_loss': 0.14959037,\n",
            " 'Loss/total_loss': 0.22633097,\n",
            " 'learning_rate': 0.07999918}\n",
            "I0819 08:27:59.536294 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.0580084,\n",
            " 'Loss/localization_loss': 0.018732186,\n",
            " 'Loss/regularization_loss': 0.14959037,\n",
            " 'Loss/total_loss': 0.22633097,\n",
            " 'learning_rate': 0.07999918}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.062s\n",
            "I0819 08:28:05.732613 136251198717952 model_lib_v2.py:705] Step 1200 per-step time 0.062s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.102532856,\n",
            " 'Loss/localization_loss': 0.022823362,\n",
            " 'Loss/regularization_loss': 0.14882532,\n",
            " 'Loss/total_loss': 0.27418154,\n",
            " 'learning_rate': 0.079996705}\n",
            "I0819 08:28:05.732988 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.102532856,\n",
            " 'Loss/localization_loss': 0.022823362,\n",
            " 'Loss/regularization_loss': 0.14882532,\n",
            " 'Loss/total_loss': 0.27418154,\n",
            " 'learning_rate': 0.079996705}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.065s\n",
            "I0819 08:28:12.227742 136251198717952 model_lib_v2.py:705] Step 1300 per-step time 0.065s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07908744,\n",
            " 'Loss/localization_loss': 0.024267992,\n",
            " 'Loss/regularization_loss': 0.14801386,\n",
            " 'Loss/total_loss': 0.2513693,\n",
            " 'learning_rate': 0.0799926}\n",
            "I0819 08:28:12.228107 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.07908744,\n",
            " 'Loss/localization_loss': 0.024267992,\n",
            " 'Loss/regularization_loss': 0.14801386,\n",
            " 'Loss/total_loss': 0.2513693,\n",
            " 'learning_rate': 0.0799926}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.057s\n",
            "I0819 08:28:17.873814 136251198717952 model_lib_v2.py:705] Step 1400 per-step time 0.057s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.067408204,\n",
            " 'Loss/localization_loss': 0.016918665,\n",
            " 'Loss/regularization_loss': 0.14718898,\n",
            " 'Loss/total_loss': 0.23151585,\n",
            " 'learning_rate': 0.07998685}\n",
            "I0819 08:28:17.874169 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.067408204,\n",
            " 'Loss/localization_loss': 0.016918665,\n",
            " 'Loss/regularization_loss': 0.14718898,\n",
            " 'Loss/total_loss': 0.23151585,\n",
            " 'learning_rate': 0.07998685}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.063s\n",
            "I0819 08:28:24.186587 136251198717952 model_lib_v2.py:705] Step 1500 per-step time 0.063s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04769406,\n",
            " 'Loss/localization_loss': 0.024792938,\n",
            " 'Loss/regularization_loss': 0.14638428,\n",
            " 'Loss/total_loss': 0.21887128,\n",
            " 'learning_rate': 0.07997945}\n",
            "I0819 08:28:24.186957 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.04769406,\n",
            " 'Loss/localization_loss': 0.024792938,\n",
            " 'Loss/regularization_loss': 0.14638428,\n",
            " 'Loss/total_loss': 0.21887128,\n",
            " 'learning_rate': 0.07997945}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.070s\n",
            "I0819 08:28:31.155251 136251198717952 model_lib_v2.py:705] Step 1600 per-step time 0.070s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09795758,\n",
            " 'Loss/localization_loss': 0.026163835,\n",
            " 'Loss/regularization_loss': 0.14555429,\n",
            " 'Loss/total_loss': 0.2696757,\n",
            " 'learning_rate': 0.079970405}\n",
            "I0819 08:28:31.156398 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.09795758,\n",
            " 'Loss/localization_loss': 0.026163835,\n",
            " 'Loss/regularization_loss': 0.14555429,\n",
            " 'Loss/total_loss': 0.2696757,\n",
            " 'learning_rate': 0.079970405}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.064s\n",
            "I0819 08:28:37.562577 136251198717952 model_lib_v2.py:705] Step 1700 per-step time 0.064s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.044537105,\n",
            " 'Loss/localization_loss': 0.01864771,\n",
            " 'Loss/regularization_loss': 0.14473258,\n",
            " 'Loss/total_loss': 0.20791739,\n",
            " 'learning_rate': 0.07995972}\n",
            "I0819 08:28:37.562882 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.044537105,\n",
            " 'Loss/localization_loss': 0.01864771,\n",
            " 'Loss/regularization_loss': 0.14473258,\n",
            " 'Loss/total_loss': 0.20791739,\n",
            " 'learning_rate': 0.07995972}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.057s\n",
            "I0819 08:28:43.215181 136251198717952 model_lib_v2.py:705] Step 1800 per-step time 0.057s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.053143177,\n",
            " 'Loss/localization_loss': 0.021954512,\n",
            " 'Loss/regularization_loss': 0.14390075,\n",
            " 'Loss/total_loss': 0.21899843,\n",
            " 'learning_rate': 0.0799474}\n",
            "I0819 08:28:43.215481 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.053143177,\n",
            " 'Loss/localization_loss': 0.021954512,\n",
            " 'Loss/regularization_loss': 0.14390075,\n",
            " 'Loss/total_loss': 0.21899843,\n",
            " 'learning_rate': 0.0799474}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.059s\n",
            "I0819 08:28:49.127951 136251198717952 model_lib_v2.py:705] Step 1900 per-step time 0.059s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08296287,\n",
            " 'Loss/localization_loss': 0.017415332,\n",
            " 'Loss/regularization_loss': 0.14309151,\n",
            " 'Loss/total_loss': 0.24346972,\n",
            " 'learning_rate': 0.07993342}\n",
            "I0819 08:28:49.128315 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.08296287,\n",
            " 'Loss/localization_loss': 0.017415332,\n",
            " 'Loss/regularization_loss': 0.14309151,\n",
            " 'Loss/total_loss': 0.24346972,\n",
            " 'learning_rate': 0.07993342}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.065s\n",
            "I0819 08:28:55.608039 136251198717952 model_lib_v2.py:705] Step 2000 per-step time 0.065s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04907864,\n",
            " 'Loss/localization_loss': 0.016405012,\n",
            " 'Loss/regularization_loss': 0.14228584,\n",
            " 'Loss/total_loss': 0.20776948,\n",
            " 'learning_rate': 0.07991781}\n",
            "I0819 08:28:55.608409 136251198717952 model_lib_v2.py:708] {'Loss/classification_loss': 0.04907864,\n",
            " 'Loss/localization_loss': 0.016405012,\n",
            " 'Loss/regularization_loss': 0.14228584,\n",
            " 'Loss/total_loss': 0.20776948,\n",
            " 'learning_rate': 0.07991781}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model"
      ],
      "metadata": {
        "id": "a8KEVVIoj0-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
      ],
      "metadata": {
        "id": "c7_LLATZj0vt"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !{command}"
      ],
      "metadata": {
        "id": "J8YBlpz7j6S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Model From Checkpoint"
      ],
      "metadata": {
        "id": "4voBZeI0jw4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ],
      "metadata": {
        "id": "XqGeHmYYM8oJ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ],
      "metadata": {
        "id": "onA27W9Cj-ek"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Image"
      ],
      "metadata": {
        "id": "RaxbJjMIkCkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "WPPTcT85kEqT"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ],
      "metadata": {
        "id": "cSOKmBfmkHBk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', '/content/Tensorflow/workspace/images/test/a (16).jpg')"
      ],
      "metadata": {
        "id": "PBXU9dCWkJLM"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(IMAGE_PATH)\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=5,\n",
        "            min_score_thresh=.8,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "gZvde5NRkKOc",
        "outputId": "893fc64e-cdc3-4094-82ce-3ce535900560"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zip Checkpoints"
      ],
      "metadata": {
        "id": "18SoNmwFnTe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
      ],
      "metadata": {
        "id": "oMEMywitlIl4"
      },
      "execution_count": 46,
      "outputs": []
    }
  ]
}